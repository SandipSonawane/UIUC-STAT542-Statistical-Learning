{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This R environment comes with many helpful analytics packages installed\n# It is defined by the kaggle/rstats Docker image: https://github.com/kaggle/docker-rstats\n# For example, here's a helpful package to load\n\nlibrary(tidyverse) # metapackage of all tidyverse packages\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nlist.files(path = \"../input\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('lets get started')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:06:41.316747Z","iopub.execute_input":"2021-11-22T02:06:41.319077Z","iopub.status.idle":"2021-11-22T02:06:41.388060Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Create splits","metadata":{}},{"cell_type":"code","source":"data <- read.table(\"../input/imdb-movies/alldata.tsv\", stringsAsFactors = FALSE,\n                  header = TRUE)\ntestIDs <- read.csv(\"../input/imdb-movies/project3_splits.csv\", header = TRUE)\nfor(j in 1:5){\n  dir.create(paste(\"split_\", j, sep=\"\"))\n  train <- data[-testIDs[,j], c(\"id\", \"sentiment\", \"review\") ]\n  test <- data[testIDs[,j], c(\"id\", \"review\")]\n  test.y <- data[testIDs[,j], c(\"id\", \"sentiment\", \"score\")]\n  \n  tmp_file_name <- paste(\"split_\", j, \"/\", \"train.tsv\", sep=\"\")\n  write.table(train, file=tmp_file_name, \n              quote=TRUE, \n              row.names = FALSE,\n              sep='\\t')\n  tmp_file_name <- paste(\"split_\", j, \"/\", \"test.tsv\", sep=\"\")\n  write.table(test, file=tmp_file_name, \n              quote=TRUE, \n              row.names = FALSE,\n              sep='\\t')\n  tmp_file_name <- paste(\"split_\", j, \"/\", \"test_y.tsv\", sep=\"\")\n  write.table(test.y, file=tmp_file_name, \n            quote=TRUE, \n            row.names = FALSE,\n            sep='\\t')\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load training data, clean html tags\n\n# j = 1\n# setwd(paste(\"split_\", j, sep=\"\"))\n# train = read.table(\"train.tsv\",\n#                    stringsAsFactors = FALSE,\n#                    header = TRUE)\n# train$review = gsub('<.*?>', ' ', train$review)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use all words\ntrain = read.table(\"../input/imdb-movies/alldata.tsv\", stringsAsFactors = FALSE,\n                  header = TRUE)\ntrain$review = gsub('<.*?>', ' ', train$review)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:06:44.346697Z","iopub.execute_input":"2021-11-22T02:06:44.380412Z","iopub.status.idle":"2021-11-22T02:06:48.900353Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"library(rsparse)\nlibrary(Rcpp)\nlibrary(text2vec)\nlibrary(glmnet)\nlibrary(pROC)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:07:01.595240Z","iopub.execute_input":"2021-11-22T02:07:01.596908Z","iopub.status.idle":"2021-11-22T02:07:01.617612Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"stop_words = c(\"i\", \"me\", \"my\", \"myself\", \n               \"we\", \"our\", \"ours\", \"ourselves\", \n               \"you\", \"your\", \"yours\", \n               \"their\", \"they\", \"his\", \"her\", \n               \"she\", \"he\", \"a\", \"an\", \"and\",\n               \"is\", \"was\", \"are\", \"were\", \n               \"him\", \"himself\", \"has\", \"have\", \n               \"it\", \"its\", \"the\", \"us\")\nit_train = itoken(train$review,\n                  preprocessor = tolower, \n                  tokenizer = word_tokenizer)\ntmp.vocab = create_vocabulary(it_train, \n                              stopwords = stop_words, \n                              ngram = c(1L,4L))\ntmp.vocab = prune_vocabulary(tmp.vocab, term_count_min = 10,\n                             doc_proportion_max = 0.5,\n                             doc_proportion_min = 0.001)\ndtm_train  = create_dtm(it_train, vocab_vectorizer(tmp.vocab))  ","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:07:02.470858Z","iopub.execute_input":"2021-11-22T02:07:02.472921Z","iopub.status.idle":"2021-11-22T02:11:03.879492Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"set.seed(9021)\ntmpfit = glmnet(x = dtm_train, \n                y = train$sentiment, \n                alpha = 1,\n                family='binomial')\ntmpfit$df","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:11:03.883394Z","iopub.execute_input":"2021-11-22T02:11:03.884987Z","iopub.status.idle":"2021-11-22T02:11:26.268432Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"which(tmpfit$df==976)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:13:50.439577Z","iopub.execute_input":"2021-11-22T02:13:50.441701Z","iopub.status.idle":"2021-11-22T02:13:50.461275Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"myvocab = colnames(dtm_train)[which(tmpfit$beta[, 36] != 0)]","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:13:22.789327Z","iopub.execute_input":"2021-11-22T02:13:22.791471Z","iopub.status.idle":"2021-11-22T02:13:22.812564Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"length(myvocab)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:14:04.262847Z","iopub.execute_input":"2021-11-22T02:14:04.265001Z","iopub.status.idle":"2021-11-22T02:14:04.285282Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# for split 1 words\ntmpfit$df[70]","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:14:04.921667Z","iopub.execute_input":"2021-11-22T02:14:04.923924Z","iopub.status.idle":"2021-11-22T02:14:04.946430Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### For testing on first split","metadata":{}},{"cell_type":"code","source":"train = read.table(\"train.tsv\",\n                   stringsAsFactors = FALSE,\n                   header = TRUE)\n train$review <- gsub('<.*?>', ' ', train$review)\n it_train = itoken(train$review,\n                    preprocessor = tolower, \n                    tokenizer = word_tokenizer)\n vectorizer = vocab_vectorizer(create_vocabulary(myvocab, \n                                                  ngram = c(1L, 2L)))\n dtm_train = create_dtm(it_train, vectorizer)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:14:11.332722Z","iopub.execute_input":"2021-11-22T02:14:11.334878Z","iopub.status.idle":"2021-11-22T02:14:11.365071Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"fit1 = cv.glmnet(x = dtm_train, \n                y = train$sentiment, \n                alpha = 0,\n                family='binomial')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = read.table(\"test.tsv\",\n                   stringsAsFactors = FALSE,\n                   header = TRUE)\n test$review <- gsub('<.*?>', ' ', test$review)\n it_test = itoken(test$review,\n                    preprocessor = tolower, \n                    tokenizer = word_tokenizer)\n vectorizer = vocab_vectorizer(create_vocabulary(myvocab, \n                                                  ngram = c(1L, 2L)))\n dtm_test = create_dtm(it_test, vectorizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit1$lambda.min","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted = predict(fit1, dtm_test, s=fit1$lambda.min, type = 'response')\n\npred = factor(ifelse(predicted > 0.5, 1, 0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y = read.table(\"test_y.tsv\",\n                   stringsAsFactors = FALSE,\n                   header = TRUE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# auc(test_y, predicted)\nauc(test_y$sentiment, predicted)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test on first split done","metadata":{}},{"cell_type":"code","source":"auc_for_splits <- rep(0, 5)\n\nfor (j in 1:5) {\n  \nsetwd('/kaggle/working')\n\n# j = 1\nsetwd(paste(\"split_\", j, sep=\"\"))\n\n\ntrain = read.table(\"train.tsv\",\n                   stringsAsFactors = FALSE,\n                   header = TRUE)\n train$review <- gsub('<.*?>', ' ', train$review)\n it_train = itoken(train$review,\n                    preprocessor = tolower, \n                    tokenizer = word_tokenizer)\n vectorizer = vocab_vectorizer(create_vocabulary(myvocab, \n                                                  ngram = c(1L, 2L)))\n dtm_train = create_dtm(it_train, vectorizer)\n\n\nfit1 = cv.glmnet(x = dtm_train, \n                y = train$sentiment, \n                alpha = 0,\n                family='binomial')\n\n\ntest = read.table(\"test.tsv\",\n                   stringsAsFactors = FALSE,\n                   header = TRUE)\n test$review <- gsub('<.*?>', ' ', test$review)\n it_test = itoken(test$review,\n                    preprocessor = tolower, \n                    tokenizer = word_tokenizer)\n vectorizer = vocab_vectorizer(create_vocabulary(myvocab, \n                                                  ngram = c(1L, 2L)))\n dtm_test = create_dtm(it_test, vectorizer)\n\n\npredicted = predict(fit1, dtm_test, s=fit1$lambda.min, type = 'response')\n\n\ntest_y = read.table(\"test_y.tsv\",\n                   stringsAsFactors = FALSE,\n                   header = TRUE)\n\n\nauc_for_splits[j] <- auc(test_y$sentiment, predicted)\n    \n    }\n\nprint(auc_for_splits)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:15:59.793417Z","iopub.execute_input":"2021-11-22T02:15:59.795335Z","iopub.status.idle":"2021-11-22T02:20:08.339952Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
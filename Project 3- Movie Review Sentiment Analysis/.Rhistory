}
return(test_pred)
}
# mypredict = function(){
#   start_date <- ymd("2011-03-01") %m+% months(2 * (t - 1))
#   end_date <- ymd("2011-05-01") %m+% months(2 * (t - 1))
#   test_current <- test %>%
#     filter(Date >= start_date & Date < end_date) %>%
#     select(-IsHoliday)
#
#   start_last_year = min(test_current$Date) - 375
#   end_last_year = max(test_current$Date) - 350
#   tmp_train <- train %>%
#     filter(Date > start_last_year & Date < end_last_year) %>%
#     mutate(Wk = ifelse(year(Date) == 2010, week(Date)-1, week(Date))) %>%
#     rename(Weekly_Pred = Weekly_Sales) %>%
#     select(-Date, -IsHoliday)
#
#   test_current <- test_current %>%
#     mutate(Wk = week(Date))
#
#   # not all depts need prediction
#   test_depts <- unique(test_current$Dept)
#   test_pred <- NULL
#
#   for(dept in test_depts){
#     train_dept_data <- train %>% filter(Dept == dept)
#     test_dept_data <- test_current %>% filter(Dept == dept)
#
#     # no need to consider stores that do not need prediction
#     # or do not have training samples
#     train_stores <- unique(train_dept_data$Store)
#     test_stores <- unique(test_dept_data$Store)
#     test_stores <- intersect(train_stores, test_stores)
#
#     for(store in test_stores){
#       tmp_train <- train_dept_data %>%
#         filter(Store == store) %>%
#         mutate(Wk = ifelse(year(Date) == 2010, week(Date)-1, week(Date))) %>%
#         mutate(Yr = year(Date))
#       tmp_test <- test_dept_data %>%
#         filter(Store == store) %>%
#         mutate(Wk = ifelse(year(Date) == 2010, week(Date)-1, week(Date))) %>%
#         mutate(Yr = year(Date))
#
#       tmp_train$Wk = factor(tmp_train$Wk, levels = 1:52)
#       tmp_test$Wk = factor(tmp_test$Wk, levels = 1:52)
#
#       train_model_matrix <- model.matrix(~ Yr + Wk, tmp_train)
#       test_model_matrix <- model.matrix(~ Yr + Wk, tmp_test)
#       mycoef <- lm(tmp_train$Weekly_Sales ~ train_model_matrix)$coef
#       mycoef[is.na(mycoef)] <- 0
#       tmp_pred <- mycoef[1] + test_model_matrix %*% mycoef[-1]
#
#       tmp_test <- tmp_test %>%
#         mutate(Weekly_Pred = tmp_pred[,1]) %>%
#         select(-Wk, -Yr)
#       test_pred <- test_pred %>% bind_rows(tmp_test)
#     }
#   }
#   return(test_pred)
# }
##### Evaluation #####
# read in train / test dataframes
train <- readr::read_csv('train_ini.csv')
# train$Date <- mdy(train$Date)
test <- readr::read_csv('test.csv')
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- rep(0, num_folds)
for (t in 1:num_folds) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
test_pred <- mypredict()
# load fold file
fold_file <- paste0('fold_', t, '.csv')
new_train <- readr::read_csv(fold_file,
col_types = cols())
train <- train %>% add_row(new_train)
# extract predictions matching up to the current fold
scoring_tbl <- new_train %>%
left_join(test_pred, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- scoring_tbl$Weekly_Pred
preds[is.na(preds)] <- 0
weights <- if_else(scoring_tbl$IsHoliday, 5, 1)
wae[t] <- sum(weights * abs(actuals - preds)) / sum(weights)
}
print(wae)
mean(wae)
lin_comb = -6 + 0.5*3 + 3.5
exp(lin_comb)/(1+exp(lin_comb))
exp(-4)/(1+exp(-4))
exp(5)/(e+exp(5))
exp(5)/(1+exp(5))
install.packages("ISLR")
# install.packages("ISLR")
library(ISLR)
data("Caravan")
Caravan
source('C:/Users/Sandi/Stats MS/542/Quiz Notebooks/Quiz 8.R', echo=TRUE)
Caravan$Purchase
Levels(Caravan$Purchase)
Caravan$Purchase
names(Caravan)
tst = Caravan[1:1000,]
trn = Caravan[1001:,]
trn = Caravan[1001:nrow(Caravan),]
tst
trn
nrow(tst)
trn = Caravan[1001:nrow(Caravan),]
tst = Caravan[1:1000,-"Purchase"]
tst = Caravan[1:1000,-Purchase]
tst = Caravan[1:1000,-Caravan$Purchase]
tst = Caravan[1:1000,-85]
tst
tst = Caravan[1:1000,-86]
tst
trn = Caravan[1001:nrow(Caravan),-86]
ytst = Caravan[1:1000, 85]
ytst
ytst = Caravan[1:1000, 86]
ytst
ytrn = Caravan[1001:nrow(Caravan), 86]
summary(ytst)
fit_glm = glm(ytrn ~ trn, family = binomial)
tst = Caravan[1:1000,]
trn = Caravan[1001:nrow(Caravan),]
fit_glm = glm(Purchase ~ ., family = binomial)
fit_glm = glm(Purchase ~ ., data=trn, family = binomial)
fit_glm = glm(Purchase ~ ., data=trn, family = binomial(link = "logit"))
fit_glm = glm(Purchase ~ ., data=trn, family = binomial)
predict(fit_glm, tst)
predict(fit_glm, tst, type = 'Class')
predict(fit_glm, tst, type = 'class')
predict(fit_glm, tst, type = 'response')
# load packages
library(tibble)
library(mlbench)
sim_logistic_data = function(sample_size = 25, beta_0 = -2, beta_1 = 3, factor = TRUE) {
x = rnorm(n = sample_size)
eta = beta_0 + beta_1 * x
p = 1 / (1 + exp(-eta))
y = rbinom(n = sample_size, size = 1, prob = p)
if (factor) {
y = factor(y)
}
tibble::tibble(x, y)
}
# simulate data for logistic regression
set.seed(3)
sim_data_factor = sim_logistic_data()
sim_data_factor
levels(sim_data_factor$y)
# simulate data for linear regression
set.seed(3)
sim_data_numeric = sim_logistic_data(factor = FALSE)
sim_data_numeric
# initial plot
plot(y ~ x, data = sim_data_numeric,
pch = 19, ylab = "Estimated Probability",
main = "Ordinary vs Logistic Regression",
ylim = c(-0.2, 1.2), cex = 1.5)
grid()
abline(h = 0, lty = 3)
abline(h = 1, lty = 3)
# E[Y | X = x] = 1 * P(Y = 1 | X = x) + 0 * P(Y = 0 | X = x) = P(Y = 1 | X = x)
# ordinary linear regression
fit_lm  = lm(y ~ x, data = sim_data_numeric)
fit_lm  = glm(y ~ x, data = sim_data_numeric)
# logistic regression
fit_glm = glm(y ~ x, data = sim_data_numeric, family = binomial)
fit_glm = glm(y ~ x, data = sim_data_numeric, family = binomial(link = "logit"))
# plot results
plot(y ~ x, data = sim_data_numeric,
pch = 19, ylab = "Estimated Probability",
main = "Ordinary vs Logistic Regression",
ylim = c(-0.2, 1.2), cex = 1.5)
grid()
abline(h = 0, lty = 3)
abline(h = 1, lty = 3)
abline(fit_lm, col = "darkorange")
curve(predict(fit_glm, data.frame(x), type = "response"),
add = TRUE, col = "dodgerblue", lty = 2)
legend("topleft", c("Ordinary", "Logistic", "Data"), lty = c(1, 2, 0),
pch = c(NA, NA, 20), lwd = 2, col = c("darkorange", "dodgerblue", "black"))
abline(h = 0.5, lty = 2)
# simulate data
set.seed(42)
blob_trn = as_tibble(mlbench.2dnormals(n = 100))
blob_tst = as_tibble(mlbench.2dnormals(n = 1000))
# check data
blob_trn
levels(blob_trn$classes)
# check balance
table(blob_trn$classes)
# initial plot
plot(x.2 ~ x.1, data = blob_trn, col = blob_trn$classes, pch = 19)
grid()
# points where we will predict
xy_vals = expand.grid(
x.1 = seq(from = -3.5, to = 3.5, by = 0.05),
x.2 = seq(from = -3.5, to = 3.5, by = 0.05)
)
head(xy_vals)
# fit model, bad
mod = glm(classes ~ ., data = blob_trn, family = binomial)
pred_xy = ifelse(predict(mod, xy_vals, type = "response") > 0.5, "lightpink", "lightgrey")
pred_xy = ifelse(predict(mod, xy_vals) > 0, "lightpink", "lightgrey")
# check predictions on plot
plot(x.2 ~ x.1, data = xy_vals, col = pred_xy,
xlim = c(-3, 3), ylim = c(-3, 3), pch = 15)
points(x.2 ~ x.1, data = blob_trn, col = blob_trn$classes, pch = 19)
# add analytic decision boundary
plot(x.2 ~ x.1, data = xy_vals, col = pred_xy,
xlim = c(-3, 3), ylim = c(-3, 3), pch = 15)
points(x.2 ~ x.1, data = blob_trn, col = blob_trn$classes, pch = 19)
abline(
a = -coef(mod)[1] / coef(mod)[3],
b = -coef(mod)[2] / coef(mod)[3],
lwd = 5, col = "white")
# check performance, miclassification
pred = factor(ifelse(predict(mod, blob_tst) > 0.0, "2", "1"))
mean(blob_tst$classes != pred)
# simulate data
set.seed(42)
circle_trn = as_tibble(mlbench.circle(n = 250))
circle_tst = as_tibble(mlbench.circle(n = 1000))
# check data
circle_trn
# check balance
table(circle_trn$classes)
# initial plot
plot(x.2 ~ x.1, data = circle_trn, col = circle_trn$classes, pch = 19)
grid()
# points where we will predict
xy_vals = expand.grid(
x.1 = seq(from = -1.1, to = 1.1, by = 0.01),
x.2 = seq(from = -1.1, to = 1.1, by = 0.01)
)
head(xy_vals)
# fit model, bad
mod_bad = glm(classes ~ ., data = circle_trn, family = binomial)
pred_bad_xy = ifelse(predict(mod_bad, xy_vals, type = "response") > 0.5, "lightpink", "lightgrey")
# check predictions on plot
plot(x.2 ~ x.1, data = xy_vals, col = pred_bad_xy,
xlim = c(-1, 1), ylim = c(-1, 1), pch = 15)
points(x.2 ~ x.1, data = circle_trn, col = circle_trn$classes, pch = 19)
# check performance, accuracy
pred_bad = factor(ifelse(predict(mod_bad, circle_tst) > 0.0, "2", "1"))
mean(circle_tst$classes == pred_bad)
# fit model, good
mod_good = glm(classes ~ poly(x.1, 2) + poly(x.2, 2) + x.1:x.2, data = circle_trn, family = binomial)
pred_good_xy = ifelse(predict(mod_good, xy_vals, type = "response") > 0.5, "lightpink", "lightgrey")
# check predictions on plot
plot(x.2 ~ x.1, data = xy_vals, col = pred_good_xy,
xlim = c(-1, 1), ylim = c(-1, 1), pch = 15)
points(x.2 ~ x.1, data = circle_trn, col = circle_trn$classes, pch = 19)
# check performance, accuracy
pred_good = factor(ifelse(predict(mod_good, circle_tst) > 0.5, "2", "1"))
mean(circle_tst$classes == pred_good)
circle_trn
levels(circle_trn$classes)
levels(trn$Purchase)
pred_ = ifelse(predict(fit_glm, tst, type = 'response') > 0.25, "Yes", "No")
fit_glm = glm(Purchase ~ ., data=trn, family = binomial)
predict(fit_glm, tst, type = 'response')
levels(trn$Purchase)
pred_ = ifelse(predict(fit_glm, tst, type = 'response') > 0.25, "Yes", "No")
pred_
sum(tst$Purchase == pred_)
tst[tst$Purchase=='No']$Purchase
tst[tst$Purchase=='No',]$Purchase
pred_[tst[tst$Purchase=='No',]$Purchase,]
pred_[tst[tst$Purchase=='No',]$Purchase$index,]
tst[tst$Purchase=='No',]$Purchase
tst[tst$Purchase=='No',]
tst[tst$Purchase=='No',]$Purchase
tst$Purchase[tst$Purchase=='No',]
tst$Purchase[tst$Purchase=='No']
tst[tst$Purchase=='No',]$Purchase
pred_[tst[tst$Purchase=='No',]$Purchase,]
tst[tst$Purchase=='No',]$Purchase
tst$Purchase=='No'
pred_[tst$Purchase=='No']
tst$Purchase=='No'
pred_[tst$Purchase=='No',]
pred_[tst$Purchase=='No']
tst$Purchase=='No'
pred_[tst$Purchase=='No']
pred_$tst$Purchase=='No'
pred_[c(tst$Purchase=='No')]
pred_[c(tst$Purchase=='No'),]
data.frame(pred_)
data.frame(pred_)[tst$Purchase=='No',]
sum(tst[tst$Purchase=='No']$Purchase == data.frame(pred_)[tst$Purchase=='No',])
tst[tst$Purchase=='No']$Purchase ==
tst[tst$Purchase=='No']$Purchase
tst[tst$Purchase=='No',]$Purchase
sum(tst[tst$Purchase=='No',]$Purchase == data.frame(pred_)[tst$Purchase=='No',])
sum(tst[tst$Purchase=='No',]$Purchase != data.frame(pred_)[tst$Purchase=='No',])
sum(tst[tst$Purchase=='Yes',]$Purchase != data.frame(pred_)[tst$Purchase=='Yes',])
pred_[c(tst$Purchase=='No'),]
tst[tst$Purchase=='No',]$Purchase
tst$Purchase=='No'
data.frame(pred_)[tst$Purchase=='No',]
sum(tst[tst$Purchase=='No',]$Purchase != data.frame(pred_)[tst$Purchase=='No',])
sum(tst[tst$Purchase=='Yes',]$Purchase != data.frame(pred_)[tst$Purchase=='Yes',])
library(pROC)
?auc
auc(fit_glm)
auc(tst$Purchase, fit_glm, auc=True)
auc(tst$Purchase, pred_)
tst$Purchase
pred_
tst$Purchase
as.matrix(pred_)
auc(as.matrix(tst$Purchase), as.matrix(pred_))
auc(as.matrix(tst$Purchase), predict(fit_glm, tst, type = 'response'))
auc(tst$Purchase, predict(fit_glm, tst, type = 'response'))
auc(tst$Purchase, predict(fit_glm, tst, type = 'response'))
sum(tst[tst$Purchase=='No',]$Purchase != data.frame(pred_)[tst$Purchase=='No',])
sum(tst[tst$Purchase=='Yes',]$Purchase != data.frame(pred_)[tst$Purchase=='Yes',])
1000-48-22
1-(48+22)/1000
######### D2
train = Caravan[1001:nrow(Caravan),]
trainX <-as.matrix(train[,-86])
trainY <- ifelse(train[,86]=="Yes", 1, 0)
stepA = step(Caravan, scope=list(upper=~., lower=~1))
stepA = step(fit_glm, scope=list(upper=~., lower=~1))
stepA
fit_glm = glm(Purchase ~ ., data=trn, family = binomial)
stepA = step(fit_glm, scope=list(upper=~., lower=~1))
fit_glm
summary(fit_glm)
stepA = step(fit_glm, scope=list(upper=~., lower=~1))
?stepAIC
??stepAIC
library(MASS)
library(MASS)
fit1 = glm(Purchase~., data=train, family=binomial)
fit2 = glm(Purchase~ 1, data=train, family=binomial)
step.model = stepAIC(fit2, direction = "forward", scope=list(upper=fit1,lower=fit2), trace=0)
step.model
step.model
step.model
mod = glm(formula = Purchase ~ PPERSAUT + MOPLLAAG + PBRAND + APLEZIER +
MRELGE + AWALAND + PFIETS + MBERBOER + MGEMLEEF + MINKGEM +
MINK123M + ABRAND + AWERKT + MGODOV + MGODPR + PWAPART +
MAUT1, family = binomial, data = train)
pred_ = ifelse(predict(mod, tst, type = 'response') > 0.25, "Yes", "No")
sum(tst[tst$Purchase=='No',]$Purchase != data.frame(pred_)[tst$Purchase=='No',])
sum(tst[tst$Purchase=='Yes',]$Purchase != data.frame(pred_)[tst$Purchase=='Yes',])
auc(tst$Purchase, predict(mod, tst, type = 'response'))
auc(tst$Purchase, predict(fit_glm, tst, type = 'response'))
?stepAIC
step.model = stepAIC(fit2, direction = "forward",
scope=list(upper=fit1,lower=fit2),
trace=0, k = log(nrow(Caravan)))
step.model
mod = glm(formula = Purchase ~ PPERSAUT + MOPLLAAG + PBRAND + APLEZIER +
MRELGE + AWALAND, family = binomial, data = train)
pred_ = ifelse(predict(mod, tst, type = 'response') > 0.25, "Yes", "No")
sum(tst[tst$Purchase=='No',]$Purchase != data.frame(pred_)[tst$Purchase=='No',])
sum(tst[tst$Purchase=='Yes',]$Purchase != data.frame(pred_)[tst$Purchase=='Yes',])
auc(tst$Purchase, predict(mod, tst, type = 'response'))
myLasso1 <- glmnet(trainX,trainY,alpha=1,lambda=0.004,family = 'binomial')
######### D4
library(glmnet)
myLasso1 <- glmnet(trainX,trainY,alpha=1,lambda=0.004,family = 'binomial')
coef(myLasso1)
test = Caravan[1:1000,]
testX <-as.matrix(test[,-86])
predict(myLasso1, testX)
predict(myLasso1, testX, type = 'response')
pred_ = ifelse(predict(myLasso1, testX, type = 'response') > 0.25, "Yes", "No")
sum(tst[tst$Purchase=='No',]$Purchase != data.frame(pred_)[tst$Purchase=='No',])
sum(tst[tst$Purchase=='Yes',]$Purchase != data.frame(pred_)[tst$Purchase=='Yes',])
auc(tst$Purchase, predict(myLasso1, tst, type = 'response'))
auc(tst$Purchase, predict(myLasso1, testX, type = 'response'))
######### D4
library(glmnet)
myLasso1 <- glmnet(trainX,trainY,alpha=1,lambda=0.004,family = 'binomial')
coef(myLasso1)
test = Caravan[1:1000,]
testX <-as.matrix(test[,-86])
predict(myLasso1, testX, type = 'response')
pred_ = ifelse(predict(myLasso1, testX, type = 'response') > 0.25, "Yes", "No")
sum(tst[tst$Purchase=='No',]$Purchase != data.frame(pred_)[tst$Purchase=='No',])
sum(tst[tst$Purchase=='Yes',]$Purchase != data.frame(pred_)[tst$Purchase=='Yes',])
auc(tst$Purchase, predict(myLasso1, testX, type = 'response'))
library("e1071")
x1=c(3,2,4,1,3,4,4)
x2=c(4,2,4,4,1,3,1)
y=c(rep(1, 4), rep(-1,3))
mydata = data.frame(y=as.factor(y),x1=x1, x2=x2)
svmfit = svm(y~., data=mydata, kernel="linear", cost=1e5, scale = FALSE)
svmfit$index
c(sum(svmfit$coefs*x1[svmfit$index]), sum(svmfit$coefs*x2[svmfit$index]))
mydata[svmfit$index,]
## change rho and coefs to be the closest integers
model=svmfit;
model$rho=-1;
model$coefs=c(1, 3, -4)
plot(x1, x2, type="n", xlim=c(0,5), ylim=c(0,5));
text(x1+0.15, x2+0.15, 1:7)
points(x1[y==1], x2[y==1], col="red", cex=1.5, pch=19)
points(x1[y==-1], x2[y==-1], col="blue", cex=1.5, pch=19)
## plot the support vectors
points(x1[model$index], x2[model$index], pch=4, cex=2);
## get the coefficients
coef1 = sum(model$coefs*x1[model$index]);
coef2 = sum(model$coefs*x2[model$index]);
## plot the three lines
abline(model$rho/coef2, -coef1/coef2, lty=1, col=1)
abline((model$rho+1)/coef2, -coef1/coef2, lty=2, col=2)
abline((model$rho-1)/coef2, -coef1/coef2, lty=2, col=2)
model$rho
coef2
-coef1
coef2
coef1
coef2
library(e1071)
spam = read.table(file="https://web.stanford.edu/~hastie/ElemStatLearn/datasets/spam.data")
names(spam)[58] = "Y"
spam$Y = as.factor(spam$Y)
testID = c(1:100, 1901:1960)
spam.test=spam[testID, ];
spam.train=spam[-testID, ];
## Linear SVM
svmfit=svm(Y ~., kernel="linear", data=spam.train, cost=1)
summary(svmfit)
table(spam.train$Y, svmfit$fitted)
svmpred=predict(svmfit, newdata=spam.test)
table(spam.test$Y, svmpred)
# training error
(2616+1534)/(2616+112+179+1534)
# training error
179+112
# cost 10
svmfit=svm(Y ~., kernel="linear", data=spam.train, cost=10)
summary(svmfit)
table(spam.train$Y, svmfit$fitted)
svmpred=predict(svmfit, newdata=spam.test)
table(spam.test$Y, svmpred)
# training error
178+110
# cost 50
svmfit=svm(Y ~., kernel="linear", data=spam.train, cost=10)
summary(svmfit)
table(spam.train$Y, svmfit$fitted)
svmpred=predict(svmfit, newdata=spam.test)
table(spam.test$Y, svmpred)
# training error
178+110
# cost 50
svmfit=svm(Y ~., kernel="linear", data=spam.train, cost=50)
summary(svmfit)
table(spam.train$Y, svmfit$fitted)
svmpred=predict(svmfit, newdata=spam.test)
table(spam.test$Y, svmpred)
# training error
179+112
## Gaussian kernel SVM
svmfit=svm(Y ~., data=spam.train, cost=1)
summary(svmfit)
table(spam.train$Y, svmfit$fitted)
svmpred=predict(svmfit, newdata=spam.test)
table(spam.test$Y, svmpred)
147+85
# cost 10
svmfit=svm(Y ~., data=spam.train, cost=10)
summary(svmfit)
table(spam.train$Y, svmfit$fitted)
svmpred=predict(svmfit, newdata=spam.test)
table(spam.test$Y, svmpred)
99+47
# cost 50
svmfit=svm(Y ~., data=spam.train, cost=50)
summary(svmfit)
table(spam.train$Y, svmfit$fitted)
svmpred=predict(svmfit, newdata=spam.test)
table(spam.test$Y, svmpred)
63+27
setwd("C:/Users/Sandi/Stats MS/542/UIUC-STAT542-Statistical-Learning/Project 3- Movie Review Sentiment Analysis")
data <- read.table("alldata.tsv", stringsAsFactors = FALSE,
header = TRUE)
testIDs <- read.csv("project3_splits.csv", header = TRUE)
for(j in 1:5){
dir.create(paste("split_", j, sep=""))
train <- data[-testIDs[,j], c("id", "sentiment", "review") ]
test <- data[testIDs[,j], c("id", "review")]
test.y <- data[testIDs[,j], c("id", "sentiment", "score")]
tmp_file_name <- paste("split_", j, "/", "train.tsv", sep="")
write.table(train, file=tmp_file_name,
quote=TRUE,
row.names = FALSE,
sep='\t')
tmp_file_name <- paste("split_", j, "/", "test.tsv", sep="")
write.table(test, file=tmp_file_name,
quote=TRUE,
row.names = FALSE,
sep='\t')
tmp_file_name <- paste("split_", j, "/", "test_y.tsv", sep="")
write.table(test.y, file=tmp_file_name,
quote=TRUE,
row.names = FALSE,
sep='\t')
}

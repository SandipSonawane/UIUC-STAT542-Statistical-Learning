{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "051d70d956493feee0c6d64651c6a088724dca2a"
   },
   "outputs": [],
   "source": [
    "# # This R environment comes with many helpful analytics packages installed\n",
    "# # It is defined by the kaggle/rstats Docker image: https://github.com/kaggle/docker-rstats\n",
    "# # For example, here's a helpful package to load\n",
    "\n",
    "# library(tidyverse) # metapackage of all tidyverse packages\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# list.files(path = \"../input\")\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T02:06:41.319077Z",
     "iopub.status.busy": "2021-11-22T02:06:41.316747Z",
     "iopub.status.idle": "2021-11-22T02:06:41.388060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"lets get started\"\n"
     ]
    }
   ],
   "source": [
    "print('lets get started')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- read.table(\"../input/imdb-movies/alldata.tsv\", stringsAsFactors = FALSE,\n",
    "                  header = TRUE)\n",
    "testIDs <- read.csv(\"../input/imdb-movies/project3_splits.csv\", header = TRUE)\n",
    "for(j in 1:5){\n",
    "  dir.create(paste(\"split_\", j, sep=\"\"))\n",
    "  train <- data[-testIDs[,j], c(\"id\", \"sentiment\", \"review\") ]\n",
    "  test <- data[testIDs[,j], c(\"id\", \"review\")]\n",
    "  test.y <- data[testIDs[,j], c(\"id\", \"sentiment\", \"score\")]\n",
    "  \n",
    "  tmp_file_name <- paste(\"split_\", j, \"/\", \"train.tsv\", sep=\"\")\n",
    "  write.table(train, file=tmp_file_name, \n",
    "              quote=TRUE, \n",
    "              row.names = FALSE,\n",
    "              sep='\\t')\n",
    "  tmp_file_name <- paste(\"split_\", j, \"/\", \"test.tsv\", sep=\"\")\n",
    "  write.table(test, file=tmp_file_name, \n",
    "              quote=TRUE, \n",
    "              row.names = FALSE,\n",
    "              sep='\\t')\n",
    "  tmp_file_name <- paste(\"split_\", j, \"/\", \"test_y.tsv\", sep=\"\")\n",
    "  write.table(test.y, file=tmp_file_name, \n",
    "            quote=TRUE, \n",
    "            row.names = FALSE,\n",
    "            sep='\\t')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data, clean html tags\n",
    "\n",
    "# j = 1\n",
    "# setwd(paste(\"split_\", j, sep=\"\"))\n",
    "# train = read.table(\"train.tsv\",\n",
    "#                    stringsAsFactors = FALSE,\n",
    "#                    header = TRUE)\n",
    "# train$review = gsub('<.*?>', ' ', train$review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T02:06:44.380412Z",
     "iopub.status.busy": "2021-11-22T02:06:44.346697Z",
     "iopub.status.idle": "2021-11-22T02:06:48.900353Z"
    }
   },
   "outputs": [],
   "source": [
    "# use all words\n",
    "train = read.table(\"../input/imdb-movies/alldata.tsv\", stringsAsFactors = FALSE,\n",
    "                  header = TRUE)\n",
    "train$review = gsub('<.*?>', ' ', train$review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T02:07:01.596908Z",
     "iopub.status.busy": "2021-11-22T02:07:01.595240Z",
     "iopub.status.idle": "2021-11-22T02:07:01.617612Z"
    }
   },
   "outputs": [],
   "source": [
    "library(rsparse)\n",
    "library(Rcpp)\n",
    "library(text2vec)\n",
    "library(glmnet)\n",
    "library(pROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T02:07:02.472921Z",
     "iopub.status.busy": "2021-11-22T02:07:02.470858Z",
     "iopub.status.idle": "2021-11-22T02:11:03.879492Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = c(\"i\", \"me\", \"my\", \"myself\", \n",
    "               \"we\", \"our\", \"ours\", \"ourselves\", \n",
    "               \"you\", \"your\", \"yours\", \n",
    "               \"their\", \"they\", \"his\", \"her\", \n",
    "               \"she\", \"he\", \"a\", \"an\", \"and\",\n",
    "               \"is\", \"was\", \"are\", \"were\", \n",
    "               \"him\", \"himself\", \"has\", \"have\", \n",
    "               \"it\", \"its\", \"the\", \"us\")\n",
    "it_train = itoken(train$review,\n",
    "                  preprocessor = tolower, \n",
    "                  tokenizer = word_tokenizer)\n",
    "tmp.vocab = create_vocabulary(it_train, \n",
    "                              stopwords = stop_words, \n",
    "                              ngram = c(1L,4L))\n",
    "tmp.vocab = prune_vocabulary(tmp.vocab, term_count_min = 10,\n",
    "                             doc_proportion_max = 0.5,\n",
    "                             doc_proportion_min = 0.001)\n",
    "dtm_train  = create_dtm(it_train, vocab_vectorizer(tmp.vocab))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T02:11:03.884987Z",
     "iopub.status.busy": "2021-11-22T02:11:03.883394Z",
     "iopub.status.idle": "2021-11-22T02:11:26.268432Z"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(9021)\n",
    "tmpfit = glmnet(x = dtm_train, \n",
    "                y = train$sentiment, \n",
    "                alpha = 1,\n",
    "                family='binomial')\n",
    "tmpfit$df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T02:13:50.441701Z",
     "iopub.status.busy": "2021-11-22T02:13:50.439577Z",
     "iopub.status.idle": "2021-11-22T02:13:50.461275Z"
    }
   },
   "outputs": [],
   "source": [
    "which(tmpfit$df==976)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T02:13:22.791471Z",
     "iopub.status.busy": "2021-11-22T02:13:22.789327Z",
     "iopub.status.idle": "2021-11-22T02:13:22.812564Z"
    }
   },
   "outputs": [],
   "source": [
    "myvocab = colnames(dtm_train)[which(tmpfit$beta[, 36] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T02:14:04.265001Z",
     "iopub.status.busy": "2021-11-22T02:14:04.262847Z",
     "iopub.status.idle": "2021-11-22T02:14:04.285282Z"
    }
   },
   "outputs": [],
   "source": [
    "length(myvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T02:14:04.923924Z",
     "iopub.status.busy": "2021-11-22T02:14:04.921667Z",
     "iopub.status.idle": "2021-11-22T02:14:04.946430Z"
    }
   },
   "outputs": [],
   "source": [
    "# for split 1 words\n",
    "tmpfit$df[70]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For testing on first split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T02:14:11.334878Z",
     "iopub.status.busy": "2021-11-22T02:14:11.332722Z",
     "iopub.status.idle": "2021-11-22T02:14:11.365071Z"
    }
   },
   "outputs": [],
   "source": [
    "train = read.table(\"train.tsv\",\n",
    "                   stringsAsFactors = FALSE,\n",
    "                   header = TRUE)\n",
    " train$review <- gsub('<.*?>', ' ', train$review)\n",
    " it_train = itoken(train$review,\n",
    "                    preprocessor = tolower, \n",
    "                    tokenizer = word_tokenizer)\n",
    " vectorizer = vocab_vectorizer(create_vocabulary(myvocab, \n",
    "                                                  ngram = c(1L, 2L)))\n",
    " dtm_train = create_dtm(it_train, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1 = cv.glmnet(x = dtm_train, \n",
    "                y = train$sentiment, \n",
    "                alpha = 0,\n",
    "                family='binomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = read.table(\"test.tsv\",\n",
    "                   stringsAsFactors = FALSE,\n",
    "                   header = TRUE)\n",
    " test$review <- gsub('<.*?>', ' ', test$review)\n",
    " it_test = itoken(test$review,\n",
    "                    preprocessor = tolower, \n",
    "                    tokenizer = word_tokenizer)\n",
    " vectorizer = vocab_vectorizer(create_vocabulary(myvocab, \n",
    "                                                  ngram = c(1L, 2L)))\n",
    " dtm_test = create_dtm(it_test, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1$lambda.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predict(fit1, dtm_test, s=fit1$lambda.min, type = 'response')\n",
    "\n",
    "pred = factor(ifelse(predicted > 0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = read.table(\"test_y.tsv\",\n",
    "                   stringsAsFactors = FALSE,\n",
    "                   header = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc(test_y, predicted)\n",
    "auc(test_y$sentiment, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on first split done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T02:15:59.795335Z",
     "iopub.status.busy": "2021-11-22T02:15:59.793417Z",
     "iopub.status.idle": "2021-11-22T02:20:08.339952Z"
    }
   },
   "outputs": [],
   "source": [
    "auc_for_splits <- rep(0, 5)\n",
    "\n",
    "for (j in 1:5) {\n",
    "  \n",
    "setwd('/kaggle/working')\n",
    "\n",
    "# j = 1\n",
    "setwd(paste(\"split_\", j, sep=\"\"))\n",
    "\n",
    "\n",
    "train = read.table(\"train.tsv\",\n",
    "                   stringsAsFactors = FALSE,\n",
    "                   header = TRUE)\n",
    " train$review <- gsub('<.*?>', ' ', train$review)\n",
    " it_train = itoken(train$review,\n",
    "                    preprocessor = tolower, \n",
    "                    tokenizer = word_tokenizer)\n",
    " vectorizer = vocab_vectorizer(create_vocabulary(myvocab, \n",
    "                                                  ngram = c(1L, 2L)))\n",
    " dtm_train = create_dtm(it_train, vectorizer)\n",
    "\n",
    "\n",
    "fit1 = cv.glmnet(x = dtm_train, \n",
    "                y = train$sentiment, \n",
    "                alpha = 0,\n",
    "                family='binomial')\n",
    "\n",
    "\n",
    "test = read.table(\"test.tsv\",\n",
    "                   stringsAsFactors = FALSE,\n",
    "                   header = TRUE)\n",
    " test$review <- gsub('<.*?>', ' ', test$review)\n",
    " it_test = itoken(test$review,\n",
    "                    preprocessor = tolower, \n",
    "                    tokenizer = word_tokenizer)\n",
    " vectorizer = vocab_vectorizer(create_vocabulary(myvocab, \n",
    "                                                  ngram = c(1L, 2L)))\n",
    " dtm_test = create_dtm(it_test, vectorizer)\n",
    "\n",
    "\n",
    "predicted = predict(fit1, dtm_test, s=fit1$lambda.min, type = 'response')\n",
    "\n",
    "\n",
    "test_y = read.table(\"test_y.tsv\",\n",
    "                   stringsAsFactors = FALSE,\n",
    "                   header = TRUE)\n",
    "\n",
    "\n",
    "auc_for_splits[j] <- auc(test_y$sentiment, predicted)\n",
    "    \n",
    "    }\n",
    "\n",
    "print(auc_for_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

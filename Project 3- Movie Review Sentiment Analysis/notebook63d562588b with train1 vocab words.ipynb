{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This R environment comes with many helpful analytics packages installed\n# It is defined by the kaggle/rstats Docker image: https://github.com/kaggle/docker-rstats\n# For example, here's a helpful package to load\n\nlibrary(tidyverse) # metapackage of all tidyverse packages\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nlist.files(path = \"../input\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('lets get started')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create splits","metadata":{}},{"cell_type":"code","source":"data <- read.table(\"../input/imdb-movies/alldata.tsv\", stringsAsFactors = FALSE,\n                  header = TRUE)\ntestIDs <- read.csv(\"../input/imdb-movies/project3_splits.csv\", header = TRUE)\nfor(j in 1:5){\n  dir.create(paste(\"split_\", j, sep=\"\"))\n  train <- data[-testIDs[,j], c(\"id\", \"sentiment\", \"review\") ]\n  test <- data[testIDs[,j], c(\"id\", \"review\")]\n  test.y <- data[testIDs[,j], c(\"id\", \"sentiment\", \"score\")]\n  \n  tmp_file_name <- paste(\"split_\", j, \"/\", \"train.tsv\", sep=\"\")\n  write.table(train, file=tmp_file_name, \n              quote=TRUE, \n              row.names = FALSE,\n              sep='\\t')\n  tmp_file_name <- paste(\"split_\", j, \"/\", \"test.tsv\", sep=\"\")\n  write.table(test, file=tmp_file_name, \n              quote=TRUE, \n              row.names = FALSE,\n              sep='\\t')\n  tmp_file_name <- paste(\"split_\", j, \"/\", \"test_y.tsv\", sep=\"\")\n  write.table(test.y, file=tmp_file_name, \n            quote=TRUE, \n            row.names = FALSE,\n            sep='\\t')\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load training data, clean html tags\n\nj = 1\nsetwd(paste(\"split_\", j, sep=\"\"))\ntrain = read.table(\"train.tsv\",\n                   stringsAsFactors = FALSE,\n                   header = TRUE)\ntrain$review = gsub('<.*?>', ' ', train$review)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"library(rsparse)\nlibrary(Rcpp)\nlibrary(text2vec)\nlibrary(glmnet)\nlibrary(pROC)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:58:02.817267Z","iopub.execute_input":"2021-11-22T01:58:02.819370Z","iopub.status.idle":"2021-11-22T01:58:02.844564Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"stop_words = c(\"i\", \"me\", \"my\", \"myself\", \n               \"we\", \"our\", \"ours\", \"ourselves\", \n               \"you\", \"your\", \"yours\", \n               \"their\", \"they\", \"his\", \"her\", \n               \"she\", \"he\", \"a\", \"an\", \"and\",\n               \"is\", \"was\", \"are\", \"were\", \n               \"him\", \"himself\", \"has\", \"have\", \n               \"it\", \"its\", \"the\", \"us\")\nit_train = itoken(train$review,\n                  preprocessor = tolower, \n                  tokenizer = word_tokenizer)\ntmp.vocab = create_vocabulary(it_train, \n                              stopwords = stop_words, \n                              ngram = c(1L,4L))\ntmp.vocab = prune_vocabulary(tmp.vocab, term_count_min = 10,\n                             doc_proportion_max = 0.5,\n                             doc_proportion_min = 0.001)\ndtm_train  = create_dtm(it_train, vocab_vectorizer(tmp.vocab))  ","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:53:14.251269Z","iopub.execute_input":"2021-11-22T01:53:14.253473Z","iopub.status.idle":"2021-11-22T01:55:21.088506Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"set.seed(9021)\ntmpfit = glmnet(x = dtm_train, \n                y = train$sentiment, \n                alpha = 1,\n                family='binomial')\ntmpfit$df","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:55:21.293932Z","iopub.execute_input":"2021-11-22T01:55:21.295667Z","iopub.status.idle":"2021-11-22T01:55:29.233824Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"myvocab = colnames(dtm_train)[which(tmpfit$beta[, 70] != 0)]","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:55:29.236457Z","iopub.execute_input":"2021-11-22T01:55:29.237964Z","iopub.status.idle":"2021-11-22T01:55:29.265254Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"length(myvocab)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:55:29.267986Z","iopub.execute_input":"2021-11-22T01:55:29.269579Z","iopub.status.idle":"2021-11-22T01:55:29.289448Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tmpfit$df[70]","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:55:29.292174Z","iopub.execute_input":"2021-11-22T01:55:29.293686Z","iopub.status.idle":"2021-11-22T01:55:29.313275Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### For testing on first split","metadata":{}},{"cell_type":"code","source":"train = read.table(\"train.tsv\",\n                   stringsAsFactors = FALSE,\n                   header = TRUE)\n train$review <- gsub('<.*?>', ' ', train$review)\n it_train = itoken(train$review,\n                    preprocessor = tolower, \n                    tokenizer = word_tokenizer)\n vectorizer = vocab_vectorizer(create_vocabulary(myvocab, \n                                                  ngram = c(1L, 2L)))\n dtm_train = create_dtm(it_train, vectorizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit1 = cv.glmnet(x = dtm_train, \n                y = train$sentiment, \n                alpha = 0,\n                family='binomial')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = read.table(\"test.tsv\",\n                   stringsAsFactors = FALSE,\n                   header = TRUE)\n test$review <- gsub('<.*?>', ' ', test$review)\n it_test = itoken(test$review,\n                    preprocessor = tolower, \n                    tokenizer = word_tokenizer)\n vectorizer = vocab_vectorizer(create_vocabulary(myvocab, \n                                                  ngram = c(1L, 2L)))\n dtm_test = create_dtm(it_test, vectorizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit1$lambda.min","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted = predict(fit1, dtm_test, s=fit1$lambda.min, type = 'response')\n\npred = factor(ifelse(predicted > 0.5, 1, 0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y = read.table(\"test_y.tsv\",\n                   stringsAsFactors = FALSE,\n                   header = TRUE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# auc(test_y, predicted)\nauc(test_y$sentiment, predicted)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:58:09.371155Z","iopub.execute_input":"2021-11-22T01:58:09.373196Z","iopub.status.idle":"2021-11-22T01:58:09.422938Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Test on first split done","metadata":{}},{"cell_type":"code","source":"for (j in 1:5) {\n  \nsetwd('/kaggle/working')\n\n# j = 1\nsetwd(paste(\"split_\", j, sep=\"\"))\n\n\ntrain = read.table(\"train.tsv\",\n                   stringsAsFactors = FALSE,\n                   header = TRUE)\n train$review <- gsub('<.*?>', ' ', train$review)\n it_train = itoken(train$review,\n                    preprocessor = tolower, \n                    tokenizer = word_tokenizer)\n vectorizer = vocab_vectorizer(create_vocabulary(myvocab, \n                                                  ngram = c(1L, 2L)))\n dtm_train = create_dtm(it_train, vectorizer)\n\n\nfit1 = cv.glmnet(x = dtm_train, \n                y = train$sentiment, \n                alpha = 0,\n                family='binomial')\n\n\ntest = read.table(\"test.tsv\",\n                   stringsAsFactors = FALSE,\n                   header = TRUE)\n test$review <- gsub('<.*?>', ' ', test$review)\n it_test = itoken(test$review,\n                    preprocessor = tolower, \n                    tokenizer = word_tokenizer)\n vectorizer = vocab_vectorizer(create_vocabulary(myvocab, \n                                                  ngram = c(1L, 2L)))\n dtm_test = create_dtm(it_test, vectorizer)\n\n\npredicted = predict(fit1, dtm_test, s=fit1$lambda.min, type = 'response')\n\n\ntest_y = read.table(\"test_y.tsv\",\n                   stringsAsFactors = FALSE,\n                   header = TRUE)\n\n\nprint(auc(test_y$sentiment, predicted))\n    \n    }","metadata":{"execution":{"iopub.status.busy":"2021-11-22T01:58:14.512739Z","iopub.execute_input":"2021-11-22T01:58:14.514741Z","iopub.status.idle":"2021-11-22T02:01:52.870390Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}